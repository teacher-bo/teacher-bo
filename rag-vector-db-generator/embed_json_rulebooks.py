import json
import os
from pathlib import Path
from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def load_json_documents(file_path: Path):
    """JSON íŒŒì¼ì„ ì½ì–´ì„œ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_path.name}): {e}")
        return []
    
    documents = []
    for item in data:
        doc_type = item.get('type', 'unknown')
        
        # ë©”íƒ€ë°ì´í„°: ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬
        metadata = item.copy()
        metadata["source_file"] = file_path.name
        
        # ChromaDB í˜¸í™˜ì„±ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
        for key, value in metadata.items():
            if isinstance(value, (list, dict)):
                metadata[key] = str(value)
        
        # 1. QA ë°ì´í„° ì²˜ë¦¬
        if doc_type == 'QA':
            question = item.get('question', '')
            answer = item.get('answer', '')
            content = f"Q: {question}\nA: {answer}"
            
        # 2. Rulebook ë°ì´í„° ì²˜ë¦¬
        elif doc_type == 'rulebook':
            title = item.get("section_title", "")
            body = item.get("content", "")
            content = f"{title}\n{body}" if title else body
            
        else:
            content = item.get('content', '')
            
        documents.append(Document(page_content=content, metadata=metadata))
    
    return documents

def main():
    print("=" * 80)
    print("ğŸ“š JSON ë£°ë¶/QA ì„ë² ë”© ì‹œìŠ¤í…œ")
    print("=" * 80)

    # ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).parent
    json_root = base_dir / "rulebooks" / "rulebook_json"
    qa_dir = json_root / "QA"
    rulebook_dir = json_root / "rulebook"
    
    # ê²Œì„ë³„ë¡œ ë¬¸ì„œ ëª¨ìœ¼ê¸° (Dictionary: game_name -> list of documents)
    games = {} 
    
    # 1. QA íŒŒì¼ íƒìƒ‰ ë° ë¡œë“œ
    if qa_dir.exists():
        for file in qa_dir.glob("*_QA.json"):
            # íŒŒì¼ëª… ê·œì¹™: {ê²Œì„ëª…}_QA.json (ì˜ˆ: rummikub_QA.json)
            game_name = file.stem.replace("_QA", "")
            docs = load_json_documents(file)
            
            if game_name not in games:
                games[game_name] = []
            games[game_name].extend(docs)
            print(f"ğŸ“– [{game_name}] QA ë°ì´í„° ë¡œë“œ: {len(docs)}ê°œ í•­ëª©")

    # 2. Rulebook íŒŒì¼ íƒìƒ‰ ë° ë¡œë“œ
    if rulebook_dir.exists():
        for file in rulebook_dir.glob("*_rulebook.json"):
            # íŒŒì¼ëª… ê·œì¹™: {ê²Œì„ëª…}_rulebook.json (ì˜ˆ: rummikub_rulebook.json)
            game_name = file.stem.replace("_rulebook", "")
            docs = load_json_documents(file)
            
            if game_name not in games:
                games[game_name] = []
            games[game_name].extend(docs)
            print(f"ğŸ“– [{game_name}] Rulebook ë°ì´í„° ë¡œë“œ: {len(docs)}ê°œ í•­ëª©")
            
    if not games:
        print("âŒ ì²˜ë¦¬í•  JSON íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print(f"   ê²½ë¡œ í™•ì¸: {json_root}")
        return

    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    print("\nğŸ¤– ì„ë² ë”© ëª¨ë¸(Upstage Solar) ì¤€ë¹„ ì¤‘...")
    embeddings = UpstageEmbeddings(model="solar-embedding-1-large-passage")
    
    # ê²Œì„ë³„ë¡œ ë²¡í„° DB ì €ì¥
    for game_name, docs in games.items():
        print(f"\nğŸš€ '{game_name}' ì²˜ë¦¬ ì‹œì‘ (ì´ ë¬¸ì„œ: {len(docs)}ê°œ)")
        
        # í…ìŠ¤íŠ¸ ë¶„í•  (JSON í•­ëª©ì´ ë„ˆë¬´ ê¸¸ ê²½ìš°ë¥¼ ëŒ€ë¹„)
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
        splits = text_splitter.split_documents(docs)
        print(f"   - ì²­í¬ ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ")

        # ë¶„í•  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        print(f"   ğŸ“‹ ì²­í¬ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):")
        for i, split in enumerate(splits[:3]):
            print(f"     [Chunk {i+1}]")
            # ë³´ê¸° ì¢‹ê²Œ ì¤„ë°”ê¿ˆ ì œê±° í›„ ì¶œë ¥
            preview_content = split.page_content[:200].replace('\n', ' ')
            print(f"     Content: {preview_content}...") 
            print(f"     Metadata: {split.metadata}")
            print("     " + "-" * 40)
        
        # ChromaDB ì €ì¥ ê²½ë¡œ ë° ì»¬ë ‰ì…˜ ì´ë¦„
        persist_directory = f"./chroma_db/{game_name}"
        collection_name = f"{game_name}_rulebook" 
        
        print(f"   - ì €ì¥ ê²½ë¡œ: {persist_directory}")
        print(f"   - ì»¬ë ‰ì…˜ëª…: {collection_name}")
        
        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥
        vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=persist_directory,
            collection_name=collection_name,
            collection_metadata={"hnsw:space": "cosine"}
        )
        print(f"âœ… '{game_name}' ì €ì¥ ì™„ë£Œ!")
        
        # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("   ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: 'ê²Œì„ ì¤€ë¹„ëŠ” ì–´ë–»ê²Œ í•´?'")
        results = vectorstore.similarity_search("ê²Œì„ ì¤€ë¹„ëŠ” ì–´ë–»ê²Œ í•´?", k=1)
        if results:
            print(f"   ğŸ‘‰ ê²°ê³¼: {results[0].page_content[:100]}...")

    print("\n" + "=" * 80)
    print("âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)

if __name__ == "__main__":
    main()
