from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
import os
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def get_available_rulebooks():
    """Get list of available rulebooks from final-rulebook directory"""
    base_dir = Path(__file__).parent
    final_dir = base_dir / "rulebooks" / "final-rulebook"
    
    if not final_dir.exists():
        return []
    
    rulebooks = []
    for file in final_dir.glob("*.rulebook.txt"):
        game_name = file.stem.replace(".rulebook", "")
        rulebooks.append({
            "name": game_name,
            "path": file
        })
    
    return rulebooks


def process_single_rulebook(game_name: str, file_path: Path):
    """Process a single rulebook and store in ChromaDB"""
    print("=" * 80)
    print(f"ğŸ“š {game_name} ë£°ë¶ ì„ë² ë”© ë° ChromaDB ì €ì¥")
    print("=" * 80)
    
    # 1. í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
    print("\n1ï¸âƒ£ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”© ì¤‘...")
    loader = TextLoader(str(file_path), encoding='utf-8')
    documents = loader.load()
    print(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")

    # 2-1. ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¡œ ë¨¼ì € ë¶„í• 
    print("\n2ï¸âƒ£ ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¡œ 1ì°¨ ë¶„í•  ì¤‘...")
    headers_to_split_on = [
        ("#", "Header 1"),
        ("##", "Header 2"),
        ("###", "Header 3"),
    ]
    markdown_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=headers_to_split_on,
        strip_headers=False  # í—¤ë”ë¥¼ ìœ ì§€
    )
    
    # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¶„í• 
    markdown_splits = markdown_splitter.split_text(documents[0].page_content)
    print(f"âœ… 1ì°¨ ë¶„í•  ì™„ë£Œ: {len(markdown_splits)}ê°œ ì„¹ì…˜")
    
    # 2-2. ê° ì„¹ì…˜ì„ ë‹¤ì‹œ ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
    print("\n3ï¸âƒ£ ê° ì„¹ì…˜ì„ 2ì°¨ ë¶„í•  ì¤‘...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,  # ì²­í¬ í¬ê¸° (300ì)
        chunk_overlap=50,  # ì²­í¬ ê°„ ê²¹ì¹¨ (ë¬¸ë§¥ ì—°ê²°)
        separators=["\n\n", "\n", " ", ""],
    )
    splits = text_splitter.split_documents(markdown_splits)
    print(f"âœ… 2ì°¨ ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬")
    
    # ë¶„í•  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    print("\nğŸ“‹ ë¶„í•  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):")
    for i, split in enumerate(splits[:]):
        print(f"\n[ì²­í¬ {i+1}]")
        print(f"ë©”íƒ€ë°ì´í„°: {split.metadata}")
        print(f"ë‚´ìš©: {split.page_content[:]}...")
        print("-" * 40)
    
    # 3. ì„ë² ë”© ëª¨ë¸ ì„¤ì • (Upstage)
    print("\n4ï¸âƒ£ ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì¤‘...")
    embeddings = UpstageEmbeddings(
        model="solar-embedding-1-large-passage"
    )
    print("âœ… Upstage Solar Embeddings ì¤€ë¹„ ì™„ë£Œ")
    
    # 4. ChromaDBì— ì €ì¥
    print("\n5ï¸âƒ£ ChromaDBì— ì €ì¥ ì¤‘...")
    persist_directory = f"./chroma_db/{game_name}"
    
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=persist_directory,
        collection_name=f"{game_name}_rulebook",
        collection_metadata={"hnsw:space": "cosine"}
    )
    print(f"âœ… ChromaDB ì €ì¥ ì™„ë£Œ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„): {persist_directory}")
    
    # 5. í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
    print("\n6ï¸âƒ£ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
    test_query = "ê²Œì„ ì¸ì›ì€ ëª‡ ëª…ì¸ê°€ìš”?"
    results = vectorstore.similarity_search(test_query, k=3)
    
    print(f"\nğŸ” ì¿¼ë¦¬: '{test_query}'")
    print("-" * 80)
    for i, doc in enumerate(results, 1):
        print(f"\n[ê²°ê³¼ {i}]")
        print(doc.page_content[:200])
        if len(doc.page_content) > 200:
            print("...")
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ {game_name} ChromaDB ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(persist_directory)}")
    print("=" * 80)
    

def main():
    """Main function to process all rulebooks"""
    print("=" * 80)
    print("ğŸ“š ë£°ë¶ ì„ë² ë”© ì‹œìŠ¤í…œ")
    print("=" * 80)
    print()
    
    # Get available rulebooks
    rulebooks = get_available_rulebooks()
    
    if not rulebooks:
        print("âŒ rulebooks/final-rulebook/ í´ë”ì— ë£°ë¶ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("   ë¨¼ì € process_rulebooks.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë£°ë¶ì„ ì²˜ë¦¬í•˜ì„¸ìš”.")
        return
    
    print(f"ğŸ“– ë°œê²¬ëœ ë£°ë¶: {len(rulebooks)}ê°œ")
    for rb in rulebooks:
        print(f"  - {rb['name']}")
    print()
    
    # Process each rulebook
    for rb in rulebooks:
        process_single_rulebook(rb['name'], rb['path'])
        print()
    
    print("=" * 80)
    print("âœ¨ ëª¨ë“  ë£°ë¶ ì²˜ë¦¬ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
