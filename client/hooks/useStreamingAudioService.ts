import { useCallback, useEffect, useRef, useState } from "react";
import {
  ExpoAudioStreamModule,
  useAudioRecorder,
  AudioDataEvent,
} from "@siteed/expo-audio-studio";
import { useSocket } from "./useSocket";
import { ENV } from "../utils/env";

interface UseAudioServiceReturn {
  isRecording: boolean;
  startRecording: () => Promise<void>;
  stopRecording: (sendToServer?: boolean) => Promise<void>;
  audioLevel: number;
  sampleRate: number;
  bufferSize: number;
  sttDatas: STTData[];
  resetSttDatas: () => void;
  reconnectSocket: () => void;
  onVadEnded?: (callback: (data: any) => void) => void;
}

interface STTData {
  clientId: string;
  isFinal: boolean;
  resultId: string;
  text: string;
  timestamp: string;
}

export const useStreamingAudioService = (): UseAudioServiceReturn => {
  const [isRecordingState, setIsRecordingState] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [sampleRate, setSampleRate] = useState(0);
  const [bufferSize, setBufferSize] = useState(0);

  const [sttDatas, setSttDatas] = useState<STTData[]>([]);
  const vadEndedCallbackRef = useRef<((data: any) => void) | null>(null);

  const onAudioDataRef = useRef<(event: AudioDataEvent) => Promise<void>>(
    async () => {}
  );
  const audioChunksRef = useRef<string[]>([]);
  const webAudioChunksRef = useRef<Float32Array>(new Float32Array(0));
  const currentSizeRef = useRef(0);
  const [socketId, setSocketId] = useState<string | null>(null);

  const {
    startRecording: startRecordingNative,
    stopRecording: stopRecordingNative,
  } = useAudioRecorder();

  const {
    sendAudioChunk: sendAudioChunkViaSocket,
    stopTranscriptionStream,
    connect: connectSocket,
    disconnect: disconnectSocket,
    reconnect: reconnectSocket,
  } = useSocket({
    socketUrl: ENV.API_BASE_URL,
    onTranscriptionResult: (data) => {
      setSttDatas((prev) => {
        const exists = prev.find((d) => d.resultId === data.resultId);
        if (exists) {
          return prev.map((d) => (d.resultId === data.resultId ? data : d));
        } else {
          return [...prev, data];
        }
      });
    },
    onTranscriptionError: (error) => {
      console.error("Transcription error handled:", error);
    },
    onVadEnded: (data) => {
      console.log("ğŸ™ï¸ VAD ended in useStreamingAudioService:", data);
      vadEndedCallbackRef.current?.(data);
    },
    onConnect: (s) => setSocketId(s.id!),
  });

  // ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ wrapper
  const sendAudioChunk = useCallback(
    (audioData: string, soundLevel: number) => {
      sendAudioChunkViaSocket(audioData, soundLevel);
    },
    [sendAudioChunkViaSocket]
  );

  // ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ í•¸ë“¤ëŸ¬
  const setupAudioDataHandler = useCallback(() => {
    onAudioDataRef.current = async (event: AudioDataEvent): Promise<void> => {
      try {
        const { data, eventDataSize } = event;
        console.debug(
          `ğŸ¤ Processing audio data: type=${typeof data}, size=${eventDataSize}`
        );

        if (!eventDataSize || eventDataSize === 0) return;

        if (typeof data === "string") {
          console.debug("ğŸ“± Processing string data (Native platform)");
          if (audioChunksRef.current) {
            audioChunksRef.current.push(data);
          }
          sendAudioChunk(data, 0);
        } else if (data instanceof Float32Array) {
          console.debug("ğŸŒ Processing Float32Array data (Web platform)");

          // Float32Arrayë¥¼ PCM 16-bitë¡œ ë³€í™˜ í›„ Base64 ì¸ì½”ë”©
          const pcmData = new Int16Array(data.length);
          for (let i = 0; i < data.length; i++) {
            const sample = Math.max(-1, Math.min(1, data[i]));
            pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7fff;
          }

          const uint8Array = new Uint8Array(pcmData.buffer);
          const base64String = btoa(String.fromCharCode(...uint8Array));
          sendAudioChunk(base64String, 0);
        } else if (
          ArrayBuffer.isView(data) &&
          (data as any).BYTES_PER_ELEMENT === 2
        ) {
          // Int16Array ì²˜ë¦¬ - ì´ë¯¸ PCM 16-bit í¬ë§·ì´ë¯€ë¡œ ì§ì ‘ Base64ë¡œ ë³€í™˜
          console.debug("Processing Int16Array data");

          const int16Data = data as Int16Array;
          const uint8Array = new Uint8Array(int16Data.buffer);
          const base64String = btoa(String.fromCharCode(...uint8Array));
          sendAudioChunk(base64String, 0);
        }
      } catch (error) {
        console.error("Error processing audio data:", error);
      }
      return Promise.resolve();
    };
  }, [sendAudioChunk]);

  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    console.log("ğŸ¬ Starting recording...");
    try {
      const { granted } = await ExpoAudioStreamModule.requestPermissionsAsync();
      if (!granted) {
        console.log("Microphone permissions denied");
        return;
      }

      setupAudioDataHandler();

      webAudioChunksRef.current = new Float32Array(0);
      audioChunksRef.current = [];
      currentSizeRef.current = 0;

      await startRecordingNative({
        sampleRate: 16000,
        onAudioStream: (event: AudioDataEvent): Promise<void> =>
          onAudioDataRef.current(event),
      });

      setSampleRate(16000);
      setBufferSize(1024);
      setIsRecordingState(true);

      // ì²« ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ ì‹œ ì„œë²„ì—ì„œ ìë™ìœ¼ë¡œ transcription stream ì‹œì‘ë¨
      console.log("Recording started with Socket.IO streaming", {
        socketId,
        sampleRate: 16000,
      });
    } catch (error) {
      console.error("Failed to start recording:", error);
      throw error;
    }
  }, [setupAudioDataHandler, socketId]);

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(
    async (sendToServer = true) => {
      try {
        if (sendToServer) {
          // transcription stream ë¨¼ì € ì¤‘ì§€
          stopTranscriptionStream();
        }

        await stopRecordingNative();
        setIsRecordingState(false);

        audioChunksRef.current = [];
        webAudioChunksRef.current = new Float32Array(0);
        setAudioLevel(0);

        console.log("Recording stopped");
      } catch (error) {
        console.error("Failed to stop recording:", error);
        throw error;
      }
    },
    [stopTranscriptionStream]
  );

  useEffect(() => {
    connectSocket();
    return () => {
      stopRecordingNative().catch(console.error);
      disconnectSocket();
      audioChunksRef.current = [];
      webAudioChunksRef.current = new Float32Array(0);
    };
  }, []);

  // VAD ended ì½œë°± ë“±ë¡ í•¨ìˆ˜
  const onVadEnded = useCallback((callback: (data: any) => void) => {
    vadEndedCallbackRef.current = callback;
  }, []);

  return {
    isRecording: isRecordingState,
    startRecording,
    stopRecording,
    audioLevel,
    sampleRate,
    bufferSize,
    sttDatas,
    resetSttDatas: () => setSttDatas([]),
    reconnectSocket,
    onVadEnded,
  };
};
